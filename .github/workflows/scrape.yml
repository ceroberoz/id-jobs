name: Daily Job Data Update

on:
  push:
    branches: [master]
  pull_request:
    branches: [master]
  schedule:
    - cron: "0 0 * * *"

jobs:
  update-job-data:
    runs-on: ubuntu-latest # Updated to latest for better package support
    permissions:
      contents: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip"

      - name: Install packages
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Playwright Browsers
        # Using npx ensures we use the version specified in requirements.txt
        run: npx playwright install --with-deps chromium

      - name: Run scraping
        env:
          PYTHONUNBUFFERED: 1
        run: |
          chmod +x ./pipeline/1_scrape.sh
          ./pipeline/1_scrape.sh

      - name: Upload and Format Data
        # Combining these prevents redundant environment setup
        env:
          GCP_JSON: ${{ secrets.GCP_JSON }}
          GOOGLE_SHEETS_ID: ${{ secrets.GOOGLE_SHEETS_ID }}
          PYTHONUNBUFFERED: 1
        run: |
          export PYTHONPATH=$PYTHONPATH:$(pwd)
          python -m pipeline.2_upload_to_sheets
          python -m pipeline.3_sheet_updater

      - name: Clean up
        if: always()
        run: rm -rf output
